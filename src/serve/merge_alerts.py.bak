#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import argparse, time
from pathlib import Path
import pandas as pd

DEF_KEEP = [
    "ts","uid","orig_h","orig_p","resp_h","resp_p","proto","service","conn_state",
    "p_cal","pred","margin","type","severity","attacker_ip","target_ip","reason","source"
]

def read_stream(path: Path, source_name: str, max_rows: int, window_sec: int) -> pd.DataFrame:
    # Boş ya da yoksa: boş df
    if not path.exists():
        return pd.DataFrame()
    try:
        if path.stat().st_size == 0:
            return pd.DataFrame()
    except Exception:
        return pd.DataFrame()

    # Bozuk/başlıksız dosyayı da tolere et
    try:
        df = pd.read_csv(path, low_memory=False)
    except pd.errors.EmptyDataError:
        return pd.DataFrame()

    if df.empty:
        return pd.DataFrame()

    # Zaman kolonu tahmini
    tcol = "ts_merged" if "ts_merged" in df.columns else (
        "ts_generated" if "ts_generated" in df.columns else (
            "ts" if "ts" in df.columns else None
        )
    )
    if tcol:
        df[tcol] = pd.to_numeric(df[tcol], errors="coerce")
        if window_sec and window_sec > 0 and df[tcol].notna().any():
            cut = df[tcol].max() - window_sec
            df = df[df[tcol] >= cut]

    # Kaynak etiketi yoksa ekle
    if "source" not in df.columns:
        df["source"] = source_name

    # Çok büyükse son max_rows
    if max_rows and len(df) > max_rows:
        df = df.tail(max_rows)

    return df

def ensure_columns(df: pd.DataFrame, keep: list[str]) -> pd.DataFrame:
    if df.empty:
        return df
    for c in keep:
        if c not in df.columns:
            df[c] = pd.NA
    return df

def apply_cooldown(out: pd.DataFrame, out_path: Path, cooldown_sec: int) -> pd.DataFrame:
    if cooldown_sec <= 0 or out.empty:
        return out
    now = time.time()
    if out_path.exists():
        try:
            prev = pd.read_csv(out_path, low_memory=False)
            if not prev.empty and "ts_merged" in prev.columns:
                recent = prev[prev["ts_merged"] >= now - cooldown_sec]
                recent_keys = set(zip(
                    recent["type"].fillna(""),
                    recent["attacker_ip"].fillna(""),
                    recent["target_ip"].fillna("")
                ))
                def is_dup(row):
                    return (str(row.get("type") or ""),
                            str(row.get("attacker_ip") or ""),
                            str(row.get("target_ip") or "")) in recent_keys
                out = out[~out.apply(is_dup, axis=1)]
        except Exception:
            pass
    return out

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--ml", default="reports/scores/alerts_stream.csv", help="ML alarm CSV yolu")
    ap.add_argument("--rules", default="reports/scores/alerts_rule_stream.csv", help="Rules alarm CSV yolu")
    ap.add_argument("--out", default="reports/scores/alerts_merged_stream.csv", help="Birleşik çıktı CSV yolu")
    ap.add_argument("--max-rows", type=int, default=250000, help="Her kaynaktan en fazla kaç satır okunacak")
    ap.add_argument("--window-sec", type=int, default=0, help="Son N saniyelik alarmları dikkate al (0=kapalı)")
    ap.add_argument("--cooldown-sec", type=int, default=0, help="Aynı (type,attacker_ip,target_ip) için tekrarlı yazımı N sn engelle (0=kapalı)")
    args = ap.parse_args()

    ml_df = read_stream(Path(args.ml), "ml", args.max_rows, args.window_sec)
    rb_df = read_stream(Path(args.rules), "rules", args.max_rows, args.window_sec)

    if ml_df.empty and rb_df.empty:
        print("[merge] no alerts to merge")
        return

    ml_df = ensure_columns(ml_df, DEF_KEEP)
    rb_df = ensure_columns(rb_df, DEF_KEEP)

    out = pd.concat([ml_df[DEF_KEEP], rb_df[DEF_KEEP]], ignore_index=True)
    out["ts_merged"] = time.time()

    out_path = Path(args.out)
    out = apply_cooldown(out, out_path, args.cooldown_sec)
    if out.empty:
        print("[merge] nothing to write after cooldown filter")
        return

    out_path.parent.mkdir(parents=True, exist_ok=True)
    header = not out_path.exists()
    out.to_csv(out_path, mode="a", index=False, header=header)
    print(f"[merge] wrote {len(out)} rows")
    try:
        print(out[["source","type","severity"]].value_counts().head(5).to_string())
    except Exception:
        pass

if __name__ == "__main__":
    main()
